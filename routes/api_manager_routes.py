from flask import Blueprint, render_template, request, redirect, jsonify, current_app, url_for
import json
import os
import requests

api_manager_bp = Blueprint("api_manager", __name__)

# Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ ÙØ§ÛŒÙ„ config Ø¯Ø± Ú©Ù†Ø§Ø± app.py
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
CONFIG_FILE = os.path.join(BASE_DIR, "api_config.json")
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"


# ----------------- Helper functions -----------------
def load_config():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ§ÛŒÙ„ JSON"""
    try:
        if not os.path.exists(CONFIG_FILE):
            print(f"[INFO] Config file not found at {CONFIG_FILE}, returning empty config")
            return {}
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            config = json.load(f)
            print(f"[INFO] Config loaded successfully from {CONFIG_FILE}")
            return config
    except Exception as e:
        print(f"[ERROR] Failed to load config: {e}")
        return {}


def save_config(data):
    """Ø°Ø®ÛŒØ±Ù‡ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø± ÙØ§ÛŒÙ„ JSON"""
    try:
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"[INFO] Config saved successfully to {CONFIG_FILE}")
        print(f"[DEBUG] Saved data: {data}")
        return True
    except Exception as e:
        print(f"[ERROR] Failed to save config: {e}")
        return False


# ----------------- UI -----------------
@api_manager_bp.route("/", methods=["GET", "POST"])
def manage_models():
    config = load_config()
    if request.method == "POST":
        model = request.form.get("model", "").strip()
        active = request.form.get("active") == "on"
        if model:
            # Ø¬Ø³Øªâ€ŒÙˆØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ø¯Ø± Ù„ÛŒØ³Øª
            model_exists = False
            for item in config:
                if isinstance(item, dict) and item.get("id") == model:
                    item["active"] = active
                    model_exists = True
                    break
            
            # Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯ Ø§Ø³ØªØŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if not isinstance(config, list):
                config = []
                config.append({"id": model, "active": active})
            
            save_config(config)
        return redirect(url_for("api_manager.manage_models"))
    return render_template("api_manager.html", config=config)


# ----------------- Model management -----------------
@api_manager_bp.route("/delete")
def delete_model():
    """Ø­Ø°Ù Ù…Ø¯Ù„ Ø§Ø² ÙØ§ÛŒÙ„ config (Ù„ÛŒØ³Øª)"""
    model = request.args.get("model")
    print(f"[INFO] Delete request received for model: {model}")
    
    if not model:
        print("[WARNING] No model parameter provided for delete")
        return redirect(url_for("api_manager.manage_models"))
    
    config = load_config()
    print(f"[DEBUG] Current config before delete (type: {type(config).__name__}): {config}")
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ùˆ Ø­Ø°Ù Ù…Ø¯Ù„ Ø§Ø² Ù„ÛŒØ³Øª
    model_found = False
    new_config = []
    
    for item in config:
        if isinstance(item, dict) and item.get("id") == model:
            model_found = True
            print(f"[INFO] Model '{model}' found and will be removed")
        else:
            new_config.append(item)
    
    if model_found:
        if save_config(new_config):
            print(f"[SUCCESS] Model '{model}' deleted and config saved successfully")
        else:
            print(f"[ERROR] Failed to save config after deleting model '{model}'")
    else:
        print(f"[WARNING] Model '{model}' not found in config list")
    
    return redirect(url_for("api_manager.manage_models"))


@api_manager_bp.route("/toggle")
def toggle_model():
    """ØªØºÛŒÛŒØ± ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ø§Ù„/ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…Ø¯Ù„ (Ø¯Ø± Ù„ÛŒØ³Øª)"""
    model = request.args.get("model")
    print(f"[INFO] Toggle request received for model: {model}")
    
    if not model:
        print("[WARNING] No model parameter provided for toggle")
        return redirect(url_for("api_manager.manage_models"))
    
    config = load_config()
    print(f"[DEBUG] Current config before toggle (type: {type(config).__name__}): {config}")
    
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ùˆ toggle Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ Ø¯Ø± Ù„ÛŒØ³Øª
    model_found = False
    
    for item in config:
        if isinstance(item, dict) and item.get("id") == model:
            model_found = True
            current_status = item.get("active", False)
            new_status = not current_status
            item["active"] = new_status
            
            print(f"[INFO] Toggling model '{model}': {current_status} -> {new_status}")
            
            if save_config(config):
                print(f"[SUCCESS] Model '{model}' toggled and config saved successfully")
            else:
                print(f"[ERROR] Failed to save config after toggling model '{model}'")
            break
    
    if not model_found:
        print(f"[WARNING] Model '{model}' not found in config list")
    
    return redirect(url_for("api_manager.manage_models"))

# ----------------- API -----------------
@api_manager_bp.route("/api/active-models")
def get_active_models():
    config = load_config()
    # ÙÛŒÙ„ØªØ± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ø§Ø² Ù„ÛŒØ³Øª
    active = [
        {"id": item.get("id"), "active": True}
        for item in config
        if isinstance(item, dict) and item.get("active")
    ]
    return jsonify(active)


@api_manager_bp.route("/api/models", methods=["GET"])
def get_models():
    try:
        config = load_config()
        # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ³Øª Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† object
        models = [{"id": item.get("id"), "object": "model", "active": item.get("active", False)} 
                  for item in config if isinstance(item, dict)]
        return jsonify({"data": models})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# OpenAI-compatible /v1/models endpoint for Neo_AutoDev
@api_manager_bp.route("/v1/models", methods=["GET"])
def get_v1_models():
    return get_active_models()


# alias Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ UI
@api_manager_bp.route("/models", methods=["GET"])
def models_alias():
    try:
        config = load_config()
        return jsonify(config or {})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@api_manager_bp.route("/api/test/<path:model>", methods=["GET"])
def test_model(model):
    api_key = os.environ.get("OPENROUTER_API_KEY") or getattr(current_app, "openrouter_api_key", None)
    if not api_key:
        return jsonify({"error": "âŒ No OPENROUTER_API_KEY set"}), 400

    payload = {
        "model": model,
        "messages": [{"role": "user", "content": "Hello, are you working?"}]
    }

    try:
        resp = requests.post(
            OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "Referer": "http://localhost:8000",
                "X-Title": "API Manager Central"
            },
            json=payload,
            timeout=20
        )
        raw = resp.json()

        output = None
        if isinstance(raw, dict):
            if "choices" in raw and raw["choices"]:
                output = raw["choices"][0]["message"]["content"]
            elif "error" in raw:
                output = f"âŒ Error: {raw['error']}"
            else:
                output = str(raw)

        return jsonify({
            "model": model,
            "output": output or "âš ï¸ No content returned from model",
            "raw": raw
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


def _handle_completion_request():
    """Shared completion logic for both /api/complete and /v1/chat/completions"""
    data = request.get_json(force=True) or {}
    model = data.get("model")
    messages = data.get("messages", [])


    config = load_config()
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù† Ù…Ø¯Ù„ Ø¯Ø± Ù„ÛŒØ³Øª
    model_active = False
    for item in config:
        if isinstance(item, dict) and item.get("id") == model and item.get("active", False):
            model_active = True
            break
    
    if not model_active:
        return jsonify({"error": {"message": "Model not active or not found", "type": "invalid_request_error"}}), 400

    api_key = os.environ.get("OPENROUTER_API_KEY") or getattr(current_app, "openrouter_api_key", None)
    if not api_key:
        return jsonify({"error": {"message": "No OPENROUTER_API_KEY set", "type": "authentication_error"}}), 500

    try:
        # Forward all request parameters to OpenRouter
        payload = {
            "model": model,
            "messages": messages
        }
        
        # Pass through any additional parameters (temperature, max_tokens, etc.)
        for key in ["temperature", "max_tokens", "top_p", "frequency_penalty", "presence_penalty", "stream"]:
            if key in data:
                payload[key] = data[key]

        
        resp = requests.post(
            OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": request.headers.get("Referer", "https://neo-autodev.koyeb.app"),
                "X-Title": "API Manager Central"
            },
            json=payload,
            timeout=30
        )
        
        # Return the raw OpenRouter response directly for Neo_AutoDev compatibility
        return jsonify(resp.json()), resp.status_code
        
    except requests.exceptions.RequestException as e:
        return jsonify({"error": {"message": str(e), "type": "api_error"}}), 500
    except Exception as e:
        return jsonify({"error": {"message": str(e), "type": "internal_error"}}), 500

@api_manager_bp.route("/api/complete", methods=["POST"])
def complete():
    """
    Compatible completion endpoint for Neo_AutoDev and manual tests.
    Simulates an AI response instead of calling external APIs.
    """
    try:
        data = request.get_json(force=True) or {}

        model = data.get("model")
        messages = data.get("messages", [])
        prompt = data.get("prompt", "")

        if not model:
            return jsonify({"error": "Missing model parameter"}), 400

        # Extract user message text
        user_message = ""
        if messages and isinstance(messages, list):
            for msg in messages:
                if msg.get("role") == "user":
                    user_message += msg.get("content", "") + "\n"
        elif isinstance(prompt, str):
            user_message = prompt

        user_message = user_message.strip() or "(no input received)"

        # Log to verify Koyeb deployment
        print(f"âœ… /api/complete endpoint triggered successfully for model: {model}")
        print(f"ğŸ—£ User message received: {user_message}")

        # Construct fake response for testing
        fake_response = {
            "choices": [
                {
                    "message": {
                        "role": "assistant",
                        "content": f"âœ… Simulated completion for model: {model}\nUser said:\n{user_message}"
                    }
                }
            ]
        }

        # âœ… Use json.dumps to ensure it's fully serialized and visible in PowerShell
        import json
        response_text = json.dumps(fake_response, ensure_ascii=False, indent=2)
        print("ğŸ“¦ Final response JSON:\n", response_text)

        return jsonify(fake_response), 200

    except Exception as e:
        print("âŒ Error in /api/complete:", str(e))
        return jsonify({"error": str(e)}), 500


# OpenAI-compatible /v1/chat/completions endpoint for Neo_AutoDev
@api_manager_bp.route("/v1/chat/completions", methods=["POST"])
def chat_completions():
    return _handle_completion_request()
